{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H4ggypglkYM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2322ae76-fdff-43d9-cdfa-08e096165a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/pca_splits-20250423T163019Z-001.zip\n",
            "  inflating: pca_splits/test_size_100000_split_5.csv  \n",
            "  inflating: pca_splits/test_size_150000_split_5.csv  \n",
            "  inflating: pca_splits/test_size_150000_split_4.csv  \n",
            "  inflating: pca_splits/test_size_150000_split_3.csv  \n",
            "  inflating: pca_splits/test_size_100000_split_3.csv  \n",
            "  inflating: pca_splits/test_size_150000_split_2.csv  \n",
            "  inflating: pca_splits/test_size_100000_split_1.csv  \n",
            "  inflating: pca_splits/test_size_100000_split_2.csv  \n",
            "  inflating: pca_splits/test_size_100000_split_4.csv  \n",
            "  inflating: pca_splits/test_size_150000_split_1.csv  \n",
            "  inflating: pca_splits/train_size_100000_split_5.csv  \n",
            "  inflating: pca_splits/train_size_100000_split_1.csv  \n",
            "  inflating: pca_splits/train_size_100000_split_2.csv  \n",
            "  inflating: pca_splits/train_size_100000_split_3.csv  \n",
            "  inflating: pca_splits/train_size_100000_split_4.csv  \n",
            "  inflating: pca_splits/train_size_150000_split_4.csv  \n",
            "Archive:  /content/pca_splits-20250423T163019Z-002.zip\n",
            "  inflating: pca_splits/train_size_150000_split_3.csv  \n",
            "  inflating: pca_splits/train_size_150000_split_5.csv  \n",
            "  inflating: pca_splits/train_size_150000_split_2.csv  \n",
            "  inflating: pca_splits/train_size_150000_split_1.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/pca_splits-20250423T163019Z-001.zip\n",
        "!unzip /content/pca_splits-20250423T163019Z-002.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "METRICS_DICT = {\n",
        "    'Accuracy': make_scorer(accuracy_score),\n",
        "    'Precision': make_scorer(precision_score, zero_division=0),\n",
        "    'Recall': make_scorer(recall_score),\n",
        "    'F1_Score': make_scorer(f1_score),\n",
        "    'ROC_AUC': make_scorer(roc_auc_score)\n",
        "}"
      ],
      "metadata": {
        "id": "zeCa5rWhzzvR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bS74sU0lkUc",
        "outputId": "d28d349c-fa2a-4f06-d91b-67c503a36535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Input folder path: /content/pca_splits\n",
            "Loading training data from: pca_splits/train_size_100000_split_1.csv\n",
            "Loaded data shapes: X=(807276, 12), y=(807276,)\n",
            "\n",
            "Preparing data for Model 1: Pre-diabetic vs. Diabetic\n",
            "Subsampling Model 1 data from 538184 to 10000 points...\n",
            "\n",
            "--- Evaluating Model: Kernel SVM (Pre-Diabetic vs. Diabetic) (Sampled) ---\n",
            "Running cross_val_predict on data shape: (10000, 12), Target unique values: [0 1]\n",
            "Detailed Cross-prediction metrics for Kernel SVM (Pre-Diabetic vs. Diabetic) (Sampled):\n",
            "  Evaluation completed successfully.\n",
            "Attempting to save results for Model 1 to detailed_metrics_pre_vs_diabetic_s100000_split1_sampled.csv...\n",
            "Successfully saved results for Model 1 to detailed_metrics_pre_vs_diabetic_s100000_split1_sampled.csv\n",
            "\n",
            "Preparing data for Model 2: Healthy vs. Diabetic\n",
            "Subsampling Model 2 data from 538184 to 10000 points...\n",
            "\n",
            "--- Evaluating Model: Kernel SVM (Healthy vs. Diabetic) (Sampled) ---\n",
            "Running cross_val_predict on data shape: (10000, 12), Target unique values: [0 1]\n",
            "Detailed Cross-prediction metrics for Kernel SVM (Healthy vs. Diabetic) (Sampled):\n",
            "  Evaluation completed successfully.\n",
            "Attempting to save results for Model 2 to detailed_metrics_healthy_vs_diabetic_s100000_split1_sampled.csv...\n",
            "Successfully saved results for Model 2 to detailed_metrics_healthy_vs_diabetic_s100000_split1_sampled.csv\n",
            "\n",
            "--- Script execution finished ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import os\n",
        "import warnings\n",
        "from sklearn.utils import resample\n",
        "\n",
        "DATASET_SIZE = 100000\n",
        "SPLIT_NUM = 1\n",
        "SAMPLE_SIZE = 10000\n",
        "TARGET_COLUMN_ORIGINAL = 'Diabetes_012'\n",
        "TARGET_COLUMNS_OHE = ['Diabetes_0', 'Diabetes_1', 'Diabetes_2']\n",
        "CV_FOLDS = 3\n",
        "RANDOM_STATE = 42\n",
        "INPUT_FOLDER = 'pca_splits'\n",
        "OUTPUT_FILE_1 = f'detailed_metrics_pre_vs_diabetic_s{DATASET_SIZE}_split{SPLIT_NUM}_sampled.csv'\n",
        "OUTPUT_FILE_2 = f'detailed_metrics_healthy_vs_diabetic_s{DATASET_SIZE}_split{SPLIT_NUM}_sampled.csv'\n",
        "\n",
        "METRICS_DICT = {\n",
        "    'Accuracy': None, 'Precision': None, 'Recall': None, 'F1 Score': None,\n",
        "    'Confusion Matrix': None, 'Sensitivity (TPR)': None, 'Specificity (TNR)': None,\n",
        "    'Precision (Class 1)': None, 'Recall (Class 1)': None\n",
        "}\n",
        "\n",
        "svm_model = SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE)\n",
        "\n",
        "def evaluate_model_get_detailed_metrics(model, X, y, cv, description):\n",
        "    \"\"\" Performs cross-validation prediction and returns detailed metrics as a dictionary. \"\"\"\n",
        "    print(f\"\\n--- Evaluating Model: {description} ---\")\n",
        "\n",
        "    if len(np.unique(y)) < 2:\n",
        "        print(f\"Skipping evaluation: Target variable has fewer than 2 classes ({np.unique(y)}).\")\n",
        "        return None\n",
        "    if X.shape[0] != len(y):\n",
        "        print(f\"Error: Mismatch between feature rows ({X.shape[0]}) and target length ({len(y)}).\")\n",
        "        return None\n",
        "    current_samples = X.shape[0]\n",
        "    if current_samples < cv:\n",
        "         print(f\"Warning: Number of samples ({current_samples}) is less than cv folds ({cv}). Adjusting cv.\")\n",
        "         cv = max(2, current_samples)\n",
        "         if current_samples < 2:\n",
        "             print(f\"Skipping evaluation: Not enough samples for cross-validation (samples={current_samples}).\")\n",
        "             return None\n",
        "\n",
        "    print(f\"Running cross_val_predict on data shape: {X.shape}, Target unique values: {np.unique(y)}\")\n",
        "\n",
        "    detailed_metrics = {}\n",
        "    try:\n",
        "        with warnings.catch_warnings():\n",
        "             warnings.simplefilter(\"ignore\", category=UserWarning)\n",
        "             y_pred = cross_val_predict(model, X, y, cv=cv, n_jobs=-1)\n",
        "\n",
        "        cm = confusion_matrix(y, y_pred)\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "        detailed_metrics['Confusion Matrix'] = str(cm.tolist())\n",
        "\n",
        "        detailed_metrics['Accuracy'] = accuracy_score(y, y_pred)\n",
        "        detailed_metrics['Sensitivity (TPR)'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "        detailed_metrics['Specificity (TNR)'] = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "        detailed_metrics['Precision (Class 1)'] = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        detailed_metrics['Recall (Class 1)'] = detailed_metrics['Sensitivity (TPR)']\n",
        "\n",
        "        report = classification_report(y, y_pred, output_dict=True, zero_division=0)\n",
        "        detailed_metrics['Precision'] = report['weighted avg']['precision']\n",
        "        detailed_metrics['Recall'] = report['weighted avg']['recall']\n",
        "        detailed_metrics['F1 Score'] = report['weighted avg']['f1-score']\n",
        "\n",
        "        print(f\"Detailed Cross-prediction metrics for {description}:\")\n",
        "        # Print metrics (removed repetitive prints, rely on return dict)\n",
        "        print(f\"  Evaluation completed successfully.\")\n",
        "        return detailed_metrics\n",
        "\n",
        "    except ValueError as ve:\n",
        "         print(f\"ValueError during cross-prediction/metric calculation for {description}: {ve}\")\n",
        "         return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during evaluation for {description}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc() # Print full traceback for unexpected errors\n",
        "        return None\n",
        "\n",
        "try:\n",
        "    print(f\"Current working directory: {os.getcwd()}\")\n",
        "    print(f\"Input folder path: {os.path.abspath(INPUT_FOLDER)}\")\n",
        "    if not os.path.isdir(INPUT_FOLDER):\n",
        "         print(f\"Warning: Input folder '{INPUT_FOLDER}' does not exist or is not a directory.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Could not get current working directory: {e}\")\n",
        "\n",
        "\n",
        "train_filename = os.path.join(INPUT_FOLDER, f\"train_size_{DATASET_SIZE}_split_{SPLIT_NUM}.csv\")\n",
        "\n",
        "if not os.path.exists(train_filename):\n",
        "    print(f\"Error: Training file not found at {train_filename}\")\n",
        "else:\n",
        "    print(f\"Loading training data from: {train_filename}\")\n",
        "    train_df = pd.read_csv(train_filename)\n",
        "\n",
        "    pca_feature_columns = [col for col in train_df.columns if col.startswith('PC')]\n",
        "    X_pca_loaded = train_df[pca_feature_columns].values\n",
        "    y_original_loaded = np.argmax(train_df[TARGET_COLUMNS_OHE].values, axis=1)\n",
        "    y_original_series = pd.Series(y_original_loaded, name=TARGET_COLUMN_ORIGINAL)\n",
        "\n",
        "    print(f\"Loaded data shapes: X={X_pca_loaded.shape}, y={y_original_series.shape}\")\n",
        "\n",
        "    output_columns = [\n",
        "        'Model', 'Dataset Size', 'Split', 'Accuracy', 'Precision', 'Recall', 'F1 Score',\n",
        "        'Confusion Matrix', 'Sensitivity (TPR)', 'Specificity (TNR)',\n",
        "        'Precision (Class 1)', 'Recall (Class 1)'\n",
        "    ]\n",
        "\n",
        "    # Model 1: Pre-diabetic (1) vs. Diabetic (2)\n",
        "    print(\"\\nPreparing data for Model 1: Pre-diabetic vs. Diabetic\")\n",
        "    filter_1 = y_original_series.isin([1, 2])\n",
        "    n_samples_1 = filter_1.sum()\n",
        "    model1_description = \"Kernel SVM (Pre-Diabetic vs. Diabetic)\"\n",
        "    detailed_metrics1 = None\n",
        "\n",
        "    if n_samples_1 > 0:\n",
        "        X1_pca = X_pca_loaded[filter_1]\n",
        "        y1_binary = y_original_series[filter_1].map({1: 0, 2: 1}).values\n",
        "\n",
        "        X_eval1, y_eval1 = None, None\n",
        "        if n_samples_1 > SAMPLE_SIZE:\n",
        "            print(f\"Subsampling Model 1 data from {n_samples_1} to {SAMPLE_SIZE} points...\")\n",
        "            X_eval1, y_eval1 = resample(\n",
        "                X1_pca, y1_binary, n_samples=SAMPLE_SIZE, random_state=RANDOM_STATE, stratify=y1_binary\n",
        "            )\n",
        "            detailed_metrics1 = evaluate_model_get_detailed_metrics(svm_model, X_eval1, y_eval1, CV_FOLDS, model1_description + \" (Sampled)\")\n",
        "        else:\n",
        "            print(f\"Using all {n_samples_1} points for Model 1 (<= SAMPLE_SIZE).\")\n",
        "            X_eval1, y_eval1 = X1_pca, y1_binary\n",
        "            detailed_metrics1 = evaluate_model_get_detailed_metrics(svm_model, X_eval1, y_eval1, CV_FOLDS, model1_description)\n",
        "\n",
        "        if detailed_metrics1 is not None:\n",
        "            try:\n",
        "                print(f\"Attempting to save results for Model 1 to {OUTPUT_FILE_1}...\")\n",
        "                results_df1 = pd.DataFrame([detailed_metrics1])\n",
        "                results_df1['Model'] = model1_description + (\" (Sampled)\" if n_samples_1 > SAMPLE_SIZE else \"\")\n",
        "                results_df1['Dataset Size'] = DATASET_SIZE\n",
        "                results_df1['Split'] = SPLIT_NUM\n",
        "                results_df1 = results_df1.reindex(columns=output_columns)\n",
        "\n",
        "                results_df1.to_csv(OUTPUT_FILE_1, index=False) # The crucial step\n",
        "                print(f\"Successfully saved results for Model 1 to {OUTPUT_FILE_1}\") # Confirmation\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\n!!!!!!!! FAILED TO SAVE CSV FOR MODEL 1 !!!!!!!!\")\n",
        "                print(f\"Error type: {type(e).__name__}\")\n",
        "                print(f\"Error message: {e}\")\n",
        "                print(f\"Attempted to save to: {os.path.abspath(OUTPUT_FILE_1)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
        "        else:\n",
        "             print(\"Skipping file save for Model 1 because evaluation failed or returned None.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Skipping Model 1 evaluation and saving: No data found for Pre-diabetic vs. Diabetic comparison in this split.\")\n",
        "\n",
        "\n",
        "    # --- Model 2: Healthy (0) vs. Diabetic (2) ---\n",
        "    print(\"\\nPreparing data for Model 2: Healthy vs. Diabetic\")\n",
        "    filter_2 = y_original_series.isin([0, 2])\n",
        "    n_samples_2 = filter_2.sum()\n",
        "    model2_description = \"Kernel SVM (Healthy vs. Diabetic)\"\n",
        "    detailed_metrics2 = None\n",
        "\n",
        "    if n_samples_2 > 0:\n",
        "        X2_pca = X_pca_loaded[filter_2]\n",
        "        y2_binary = y_original_series[filter_2].map({0: 0, 2: 1}).values\n",
        "\n",
        "        X_eval2, y_eval2 = None, None\n",
        "        if n_samples_2 > SAMPLE_SIZE:\n",
        "            print(f\"Subsampling Model 2 data from {n_samples_2} to {SAMPLE_SIZE} points...\")\n",
        "            X_eval2, y_eval2 = resample(\n",
        "                X2_pca, y2_binary, n_samples=SAMPLE_SIZE, random_state=RANDOM_STATE, stratify=y2_binary\n",
        "            )\n",
        "            detailed_metrics2 = evaluate_model_get_detailed_metrics(svm_model, X_eval2, y_eval2, CV_FOLDS, model2_description + \" (Sampled)\")\n",
        "        else:\n",
        "            print(f\"Using all {n_samples_2} points for Model 2 (<= SAMPLE_SIZE).\")\n",
        "            X_eval2, y_eval2 = X2_pca, y2_binary\n",
        "            detailed_metrics2 = evaluate_model_get_detailed_metrics(svm_model, X_eval2, y_eval2, CV_FOLDS, model2_description)\n",
        "\n",
        "        if detailed_metrics2 is not None:\n",
        "             try:\n",
        "                print(f\"Attempting to save results for Model 2 to {OUTPUT_FILE_2}...\")\n",
        "                results_df2 = pd.DataFrame([detailed_metrics2])\n",
        "                results_df2['Model'] = model2_description + (\" (Sampled)\" if n_samples_2 > SAMPLE_SIZE else \"\")\n",
        "                results_df2['Dataset Size'] = DATASET_SIZE\n",
        "                results_df2['Split'] = SPLIT_NUM\n",
        "                results_df2 = results_df2.reindex(columns=output_columns)\n",
        "\n",
        "                results_df2.to_csv(OUTPUT_FILE_2, index=False) # The crucial step\n",
        "                print(f\"Successfully saved results for Model 2 to {OUTPUT_FILE_2}\") # Confirmation\n",
        "\n",
        "             except Exception as e:\n",
        "                print(f\"\\n!!!!!!!! FAILED TO SAVE CSV FOR MODEL 2 !!!!!!!!\")\n",
        "                print(f\"Error type: {type(e).__name__}\")\n",
        "                print(f\"Error message: {e}\")\n",
        "                print(f\"Attempted to save to: {os.path.abspath(OUTPUT_FILE_2)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc() # Print full traceback for saving error\n",
        "                print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\\n\")\n",
        "        else:\n",
        "             print(\"Skipping file save for Model 2 because evaluation failed or returned None.\")\n",
        "    else:\n",
        "        print(\"Skipping Model 2 evaluation and saving: No data found for Healthy vs. Diabetic comparison in this split.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}